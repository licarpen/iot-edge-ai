In this exercise, you'll convert an ONNX Model into an Intermediate Representation using the Model Optimizer. You can find the related documentation here.

For this exercise, first download the bvlc_alexnet model from here. Use the tar -xvf command with the downloaded file to unpack it.

Follow the documentation above and feed in the ONNX model to the Model Optimizer.

If the conversion is successful, the terminal should let you know that it generated an IR model. The locations of the .xml and .bin files, as well as execution time of the Model Optimizer, will also be output.

PyTorch models
Note that we will only cover converting directly from an ONNX model here. If you are interested in converting a PyTorch model using ONNX for use with OpenVINO, check out this link for the steps to do so. From there, you can follow the steps in the rest of this exercise once you have an ONNX model.

Solution:

Here's what I entered to convert the AlexNet model from ONNX:

python /opt/intel/openvino/deployment_tools/model_optimizer/mo.py --input_model model.onnx

